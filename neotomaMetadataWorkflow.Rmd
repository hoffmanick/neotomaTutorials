---
title: "Neotoma Metadata Workflow"
author: "Nick Hoffman"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    highlight: pygment
    keep_md: no
    toc: true
    number_sections: true
    toc_depth: 1
    toc_float: true
    theme: journal
editor_options:
    chunk_output_type: inline
---

<style type="text/css">
h2, h3, h4, h5, h6 {
  counter-reset: section;
}
p {
  font-size:18px;
}

ul {
  font-size:18px;
}

li {
  font-size:18px;
}
table {
   padding: 0;border-collapse: collapse;
   layout: fixed;
   width: 90%; }
table tr {
   border-top: 1px solid #cccccc;
   background-color: white;
   margin: 0;
   padding: 0; }
table tr:nth-child(2n) {
   background-color: #f8f8f8; }
table tr th {
   font-weight: bold;
   border: 1px solid #cccccc;
   margin: 0;
   padding: 6px 13px; }
table tr td {
   border: 1px solid #cccccc;
   margin: 0;
   padding: 6px 13px; }
table tr th :first-child, table tr td :first-child {
   margin-top: 0; }
table tr th :last-child, table tr td :last-child {
   margin-bottom: 0; }
.html-widget {
    margin: auto;
}
</style>

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Through its curation of much heterogeneous paleodata and metadata, the Neotoma Paleoecology Database empowers users to generate new paleobiological insights. The extent of the metadata that Neotoma curates may not be obvious to its users, because it is not all exposed in the Neotoma Explorer app, or even in the functions provided by the neotoma2 R package. This tutorial will walk you through how to search for metadata that you may like to take advantage of in your work, with a focus on site and core location.

```{r packages, warning=FALSE, message=FALSE}

library(neotoma2)
library(tidyverse)
library(DT)
library(geojsonsf)
library(sf)
library(leaflet)
library(jsonlite)
library(httr)
library(ggplot2)
library(analogue)


```

# Getting Data

First we want to grab some sites that we care about. This tutorial assumes you already know how to get data through the neotoma2 R package. If you need a refresher, please see this [tutorial](https://open.neotomadb.org/EPD_binder/simple_workflow.html).  

We'll look for sites from Lake Tanganyika, to start with. We grab the sites, and then we use the neotoma2::plotLeaflet() function to see where those sites (nominally) are.

```{r get-data, echo=TRUE, warning=FALSE}

tanganyikaSites = get_sites(sitename = "%Tanganyika%")


plotLeaflet(tanganyikaSites)
```

We found four sites, and they seem to be located along the middle of the lake. But we need to be careful here for two related reasons:

1. the plotLeaflet() function will plot all sites as points, even if they are really stored in Neotoma as polygons, and 
2. the coordinates of site objects in Neotoma are not necessarily the precise locations where cores have been taken. Neotoma stores core location information in a separate object, the collection unit. 

Let's tackle these two complications one by one.

# Points and polygons

Like we said, the plotLeaflet() function is a wonderful and convenient tool for understanding general site location, but it can sometimes mislead us into thinking that a site is described with more precision in Neotoma than it actually is. This isn't always a problem - sometimes all we need is general site location. But if we're trying to be careful about site location - if, for instance, we're doing an analysis that is sensitive to small-scale spatial variation - then we're going to want to grab more authoritative Neotoma metadata about site location. We can do this through one of [Neotoma's API calls](https://api.neotomadb.org/api-docs/).

In particular, we're going to use an API that requires a Neotoma siteid, or comma-separated string of siteids, as an input, and outputs site and dataset metadata. First we'll format the siteids from the Tanganyika sites we found earlier as a comma-separated string, and then we'll paste them into the particular API call we'd like to make. We send a GET request and unpack the response with the content() function, focusing just on what's under the <i>data</i> header. And we can look at the beginning of our output (which we call siteMetadata).

```{r api-sites, echo=TRUE, warning=FALSE}


siteidString = paste0(as.data.frame(tanganyikaSites)$siteid,collapse=",")

apiCall = paste0('https://api.neotomadb.org/v2.0/data/sites/',siteidString,'/datasets')


response = GET(apiCall)

siteMetadata = content(response)$data


siteMetadata[[1]]$site[1:5]
```

siteMetadata is a list of ... well ... site metadata. Even just looking at the first few entries of this list, we can see that at least one site that plotLeaflet() rendered as a point is in fact a polygon. But the list structure is hard to read. Let's reformat this list as a datatable, and for now, let's only keep site metadata, not dataset metadata. Because we're only keeping site metadata, some of our entries will be duplicated - we can keep just the distinct entries.

```{r metadata-to-table, warning=FALSE}

idx = 0

for (i in seq(length(siteMetadata))) {
  for (j in seq(length(siteMetadata[[i]]$site$datasets))) {
    idx = idx + 1
  }
}


siteMetadata_mat = matrix(nrow=idx,ncol=10)

idx2 = 0
for (i in seq(length(siteMetadata))) {
  for (j in seq(length(siteMetadata[[i]]$site$datasets))) {
    idx2 = idx2 + 1
    for (k in seq(10)) {
      if (!is.null(siteMetadata[[i]]$site[[k]])) {
        siteMetadata_mat[[idx2, k]] = siteMetadata[[i]]$site[[k]]
      }
    }
    
 #    if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$doi[[1]])) {
 #       siteMetadata_mat[[idx2, 11]] = siteMetadata[[i]]$site$datasets[[j]]$doi[[1]]
  #   }
  #  
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[1]])) {
  #      siteMetadata_mat[[idx2, 12]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[1]]
  #  }
  #  
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[2]])) {
  #      siteMetadata_mat[[idx2, 13]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[2]]
  #    }
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[3]])) {
  #      siteMetadata_mat[[idx2, 14]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[3]]
  #  }
  #  
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$database)) {
  #      siteMetadata_mat[[idx2, 15]] = siteMetadata[[i]]$site$datasets[[j]]$database
  #  }
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetid)) {
  #      siteMetadata_mat[[idx2, 16]] = siteMetadata[[i]]$site$datasets[[j]]$datasetid
  #  }
  #  
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetpi[[1]]$contactname)) {
  #      siteMetadata_mat[[idx2, 17]] = siteMetadata[[i]]$site$datasets[[j]]$datasetpi[[1]]$contactname
  #  }
  #  
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasettype)) {
  #      siteMetadata_mat[[idx2, 18]] = siteMetadata[[i]]$site$datasets[[j]]$datasettype
  #  }
  #  
  #  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetnotes)) {
  #      siteMetadata_mat[[idx2, 19]] = siteMetadata[[i]]$site$datasets[[j]]$datasetnotes
  #  }
  }
}


siteMetadata_df = as.data.frame(siteMetadata_mat)

names(siteMetadata_df) = c("siteid","sitename","sitedescription","sitenotes","geography","altitude","collectionunitid","collectionunit","handle","unittype")

#names(siteMetadata_df) = c("siteid","sitename","sitedescription","sitenotes","geography","altitude","collectionunitid","collectionunit","handle","unittype","dataset_doi","dataset_agerange_units","dataset_ageold","dataset_ageyoung","database","datasetid","datasetpi","datasettype","datasetnotes")

siteMetadata_df = distinct(siteMetadata_df)

#just first ten cols
datatable(siteMetadata_df[1:10],rownames=FALSE)

```

You'll notice that even after removing duplicate entries, we have eleven rows, but only four sites. This is because the metadata under the site header also includes collectionunit information - more on the collecitonunits soon - and each of these sites is associated with between 1 and 4 collection units.


Before talking about the collectionunits in more detail, let's map the new site location metadata, to check whether in fact they are points or polygons. In order to do this, we'll use the geojson_sf() function to convert geography column of our siteMetadata_df dataframe into an sf (simple features) object, and rebind that sf object to the rest of the dataframe. Then we'll split apart those sites that have point geometry (pointSites) from those which have polygon geometry (polySites), keeping only those rows with distinct siteids, and plot both objects in a leaflet plot.

```{r geo-revisited, warning=FALSE}



siteGeo_sf = geojson_sf(siteMetadata_df$geography)

siteMetadata_sf = cbind(siteGeo_sf,siteMetadata_df)

pointSites = siteMetadata_sf[st_geometry_type(siteMetadata_sf) == "POINT",] %>% distinct(siteid, .keep_all = TRUE)
polySites = siteMetadata_sf[st_geometry_type(siteMetadata_sf) == "POLYGON",] %>% distinct(siteid, .keep_all = TRUE)

leaflet() %>%
  addTiles() %>%
  addPolygons(data = polySites, 
              color = "red", 
              weight = 2, 
              fillColor = "orange", 
              fillOpacity = 0.15, 
              popup = ~sitename)  %>%
  addCircleMarkers(data = pointSites, 
                   radius = 5, 
                   color = "blue", 
                   fillColor = "blue", 
                   fillOpacity = 0.7, 
                   stroke = FALSE, 
                   popup = ~sitename)

```


Aha: three of our four sites are in fact polygons, not points ! The site object in Neotoma may only bound the locality in which an investigation has occurred in the most general terms. 

So we've learned that the site isn't the right level at which to be careful about pollen core location. Where, then, do we find the information about core location?? It turns out we need to look to the collectionunits table, accessible through an API. 

# The collectionunits table

The collectionunits table is the place to go to learn about core-specific metadata, including precise core location. In order to access the collectionunits associated with our Tanganyika sites, we first need to download the entire collection-units table. Then we'll filter for the collection units we care about. Below, we grab the collectionunits table as a list, reformat it into a dataframe, and then an sf object, and plot it on top of our map.


```{r collectionunits, warning=FALSE}


text="collectionunits"
collunits = content(GET(paste0('https://api.neotomadb.org/v2.0/data/dbtables/',text,'?count=false&limit=99999&offset=0')))$data



collunit_mat = matrix(nrow=length(collunits),ncol=20)

for (i in seq(length(collunits))) {
  for (j in seq(20)) {
    if (!is.null(collunits[[i]][[j]])) {
      collunit_mat[[i,j]] = collunits[[i]][[j]]
    }
  }
}

collunit_df = collunit_mat %>% as.data.frame()

names(collunit_df) = c("collectionunitid","handle","siteid","colltypeid","depenvtid","collunitname","colldate","colldevice","gpslatitude","gpslongitude","gpsaltitude","gpserror","waterdepth","substrateid","slopeaspect","slopeangle","location","notes","recdaterecreated","recdatemodified")


filtered_colls = collunit_df %>% dplyr::filter(collectionunitid %in% siteMetadata_df$collectionunitid) 
filteredColl_sf = collunit_df %>% dplyr::filter(collectionunitid %in% siteMetadata_df$collectionunitid) %>% st_as_sf(coords=c("gpslongitude","gpslatitude"), crs="WGS84")

#just first ten cols
datatable(st_drop_geometry(filteredColl_sf)[c(1:3,5:10,15)],rownames=FALSE)



pal <- colorFactor(palette = "Set1", domain = siteMetadata_df$siteid)

leaflet() %>%
  addTiles() %>%
  addPolygons(data = polySites, 
              color = "red", 
              weight = 2, 
              fillColor = ~pal(siteid), 
              fillOpacity = 0.45, 
              popup = ~siteid)  %>%
  addCircleMarkers(data = pointSites, 
                   radius = 5, 
                   color = "black", 
                   fillColor = ~pal(siteid), 
                   fillOpacity = 0.7, 
                   stroke = TRUE, 
                   weight = 1,
                   popup = ~siteid)   %>% 
  addCircleMarkers(data = filteredColl_sf, 
                   radius = 3, 
                   color = "white", 
                   fillColor = ~pal(siteid), 
                   fillOpacity = 1, 
                   stroke = TRUE,
                   weight = 1,
                   popup = ~collectionunitid)

```


Well ! With the exception of site "Lake Tanganyika [SD cores]" (our only point site), there are mismatches between general site location and core location. 

This raises the question, at what spatial resolution, and for what sorts of analyses, do these mismatches start to matter? See this [demonstration](coordinatesMatter.html) for one answer.

# Further exploration of Neotoma metadata

We were able to find important location information by downloading the entire collectionunits table, and we could do that because we knew about the existence of this table. But Neotoma has a sophisticated data model - there are tables with relevant information whose existence we're not going to know about.  

Luckily, Neotoma's data model is open, and available for exploration at [Open Neotoma](https://open.neotomadb.org/dbschema/ndb/). We can use this resource to explore further metadata. If for instance, we wanted to see what other information is connected to our collection units, we can navigate to the [page](https://open.neotomadb.org/dbschema/ndb/tables/collectionunits.html) in Open Neotoma on the collection units tables. This page provides the names and definitions of the fields in the collection units table, and if you scroll to the bottom of the page, you can also see what other tables the collection units table is connected to through primary/foreign key pairs.

<img src="./images/collectionunits_relationships.JPG" >

If we wanted to know more about the substrate for our collection units, we could download the rocktypes table that we see referenced on this page (using the same download-table API call from earlier) and filter the table for the relevant substrate ids from our collection units.

```{r further-explore}

text2="rocktypes"
rocktypes = content(GET(paste0('https://api.neotomadb.org/v2.0/data/dbtables/',text2,'?count=false&limit=99999&offset=0')))$data

rock_mat = matrix(nrow = length(rocktypes),ncol=6)
for (i in seq(length(rocktypes))) {
  for (j in seq(6)) {
    if (!is.null(rocktypes[[i]][[j]])) {
      rock_mat[i,j] = rocktypes[[i]][[j]]
    }
  }
}

rock_df = as.data.frame(rock_mat)

names(rock_df) = c("rocktypeid","rocktype","higherrocktypeid","description","recdatecreated","recdatemodified")

filtered_colls = filtered_colls %>% left_join(rock_df,by=join_by("substrateid" == "rocktypeid"))

datatable(filtered_colls[c(1,3,6,14,15,16,21,22,23)],rownames=FALSE)

```

If we do that, we find the substrate is either clay or mud, silt, or unrecorded. I guess that's not too surprising for sediment cores !

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>