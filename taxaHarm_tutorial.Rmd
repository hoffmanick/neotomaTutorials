---
title: "Taxon Harmonization"
author: "Nick Hoffman"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    highlight: pygment
    keep_md: no
    toc: true
    number_sections: true
    toc_depth: 1
    toc_float: true
    theme: journal
editor_options:
    chunk_output_type: inline
---

<style type="text/css">
h2, h3, h4, h5, h6 {
  counter-reset: section;
}
p {
  font-size:18px;
}

ul {
  font-size:18px;
}

li {
  font-size:18px;
}
table {
   padding: 0;border-collapse: collapse;
   layout: fixed;
   width: 90%; }
table tr {
   border-top: 1px solid #cccccc;
   background-color: white;
   margin: 0;
   padding: 0; }
table tr:nth-child(2n) {
   background-color: #f8f8f8; }
table tr th {
   font-weight: bold;
   border: 1px solid #cccccc;
   margin: 0;
   padding: 6px 13px; }
table tr td {
   border: 1px solid #cccccc;
   margin: 0;
   padding: 6px 13px; }
table tr th :first-child, table tr td :first-child {
   margin-top: 0; }
table tr th :last-child, table tr td :last-child {
   margin-bottom: 0; }
.html-widget {
    margin: auto;
}
</style>

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

When performing large-scale syntheses of pollen data, it is usually necessary to harmonize taxonomic systems across datasets. There are a few different reasons why taxon harmonization is important.

1. Taxonomies have changed over the time that people have been doing pollen analysis in Africa. (example for Olea?)
2. A particular taxon can be identified to varying resolution. For instance, Olea capensis pollen can be identified to a species-level morphotype, but sometiems analysts will only identify it to the genus level. Depending on the nature of your analysis, you may therefore want to aggregate all the Olea capensis pollen in your data to a broader Olea category.
3. Many plant taxa are cosmopolitan. Across a regional or continental synthesis, it isn't obvious how you should deal with the question of splitting and lumping. In the case of Olea, depending on your question, you may want to treat the population from southern Africa as distinct from the east African population - or you may not. This is something you should be intentional about. 

There are multiple good ways to harmonize. It all depends on what best suits the analysis you intend. 

Luckily for us, The African Pollen Database curates a valuable table for assisting in taxa harmonization across African pollen. This guide will walk you through use of the APD taxa harmonization table with a simple example.

## Packages and Data

We'll first load up some packages we're going to be using, and then grab some pollen data to play with from Neotoma.

```{r packages,message=FALSE,warning=FALSE}

library(neotoma2)
library(tidyverse)
library(sf)
library(geojsonsf)
library(httr)
library(jsonlite)
library(stringr)
library(ggplot2)
library(leaflet)
library(tmap)
library(rosm)
library(osmdata)
library(DT)
```

We make a bounding box that encompasses all of Africa. Then we grab all Neotoma sites from that box, and filter for just those datasetids that concern pollen. Then we use the Neotoma2 package to download all of those pollen data.

```{r get-data, warning = FALSE, message = FALSE}
lats = c(38, 38, -36, -36)
lons = c(-18, 52, 52, -18) # Reordered for a rectangle

# Create a data frame with coordinates
coordinates = data.frame(lat = lats, lon = lons)

# Convert to sf object and create a polygon
coordinates_sf = coordinates %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%
  summarise(geometry = st_combine(geometry)) %>%
  st_cast("POLYGON")

# Plot to check
tm_shape(osm.raster(coordinates_sf)) +
  tm_rgb() +
  tm_shape(coordinates_sf) +
  tm_polygons(alpha = 0.5)


coord_json = sf_geojson(coordinates_sf)


altmin = 000 #m

sites = content(GET(paste0("https://api.neotomadb.org/v2.0/data/sites?altmin=",altmin,"&loc=",coord_json,"&limit=9999&offset=0")))$data


idx = 0
for (i in seq(length(sites))) {
  for (j in seq(length(sites[[i]]$collectionunits))) {
    for (k in seq(length(sites[[i]]$collectionunits[[j]]$datasets))) {
    idx = idx + 1
    }
    }
}


sites_mat = matrix(nrow=idx,ncol=11)

idx2 = 0
for (i in seq(length(sites))) {
  for (j in seq(length(sites[[i]]$collectionunits))) {
    for (k in seq(length(sites[[i]]$collectionunits[[j]]$datasets))) {
    idx2 = idx2 + 1
    for (m in seq(5)) {
      if (!is.null(sites[[i]][[m]])) {
        sites_mat[[idx2, m]] = sites[[i]][[m]]
      }
    }
    
     if (!is.null(sites[[i]]$collectionunits[[j]]$handle)) {
        sites_mat[[idx2,6]] = sites[[i]]$collectionunits[[j]]$handle
     }
       if (!is.null(sites[[i]]$collectionunits[[j]]$collectionunit)) {
        sites_mat[[idx2,7]] = sites[[i]]$collectionunits[[j]]$collectionunit
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$collectionunitid)) {
        sites_mat[[idx2,8]] = sites[[i]]$collectionunits[[j]]$collectionunitid
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$collectionunittype)) {
        sites_mat[[idx2,9]] = sites[[i]]$collectionunits[[j]]$collectionunittype
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasetid)) {
        sites_mat[[idx2,10]] = sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasetid
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasettype)) {
        sites_mat[[idx2,11]] = sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasettype
       }
    }
  }
}

sites_df = as.data.frame(sites_mat)

names(sites_df) = c("siteid","sitename","sitedescription","geography","altitude","handle","collectionunit","collectionunitid","collectionunittype","datasetid","datasettype")


datasetids = sites_df %>% dplyr::filter(datasettype == "pollen") %>% dplyr::distinct(datasetid)

datasets_neo = get_datasets(as.numeric(datasetids$datasetid),all_data=TRUE)

data = samples(get_downloads(datasets_neo,all_data=TRUE))

```

Now that we have our data, let's grab our harmonization table. That comes from the [African Pollen Database](https://africanpollendatabase.ipsl.fr/)'s website, and you can download it directly through the "download table [.csv]" button on [this page](https://africanpollendatabase.ipsl.fr/#/taxon-dict). 

We'll manipulate the data little bit to make sums of pollen counts by site and age. Then we'll divide every pollen count by the appropriate sum in order to get proportion data. 


```{r part-two, warning = FALSE, message = FALSE}

apd_harmTable = read.csv("APD_dictionnary_export.csv",row.names=NULL,sep=";")


poltots = data %>% left_join(apd_harmTable, by=join_by(variablename == Taxon..original.name.)) %>% group_by(siteid,age) %>% summarize(poltot = sum(value))

pollendata = data  %>% left_join(poltots) %>% group_by(siteid,age,variablename) %>% summarize(prop = value/poltot, lat=lat, elev = elev) %>% left_join(apd_harmTable, by=join_by(variablename == Taxon..original.name.))


```

# Olea capensis elevation shifts

Let's say we're interested in latitudinal shifts in Olea capensis over time. We can filter our data for just those instances where Olea capensis is greater than 5% of the pollen assemblage with the code below. We filter for when the variablename is "Olea capensis" and when its proportion is greater than 0.05. When I do that, in November 2024, I get 127 instances of greater than 5% Olea capensis.

When we plot the latitude of those occurrences over time, we get a curve that shows most reliably an increase in latitude for Olea capensis, over the past 20,000 years. [connection to deglaciation?? i'm used to saying 'things move north when it warms up - but idk if that really applies in these latitudes']


``` {r partthefifth, warning = FALSE, message = FALSE}
oleacap_noHarm = pollendata %>% dplyr::filter(variablename == "Olea capensis") %>% dplyr::filter(!is.na(prop)) %>%
  dplyr::filter(prop > 0.05)


ggplot() +
  geom_point(mapping=aes(x=age,y=elev),alpha=0.8,color='red',data=oleacap_noHarm) +
  scale_x_reverse() +
  theme_bw()




```

The story we got from those Olea capensis data seems reliable. But we're leaving data on the table if we're not thinking about taxon harmonization. 

```{r part-three, warning = FALSE, message = FALSE}


oleatable = pollendata %>% dplyr::filter(str_detect(variablename,"Olea")) %>%
  dplyr::filter(str_detect(variablename,"capensis")) %>% group_by(variablename) %>% count() %>% left_join(apd_harmTable, by=join_by(variablename == Taxon..original.name.)) %>% arrange(desc(n))
 
datatable(oleatable[c(1,3,2)],rownames=FALSE)

```

Consider the table above that shows all number of occurrences for all the different taxa with the words "Olea" and "capensis" somewhere in them from our dataset, alongside the recommended nomenclature for that taxon from the APD taxon harmonization table. "Olea capensis" is the most commonly used taxon - but there are other categories which we may want include in our analysis. In particular, the taxon is often referred to as "Olea capensis-type" to communicate that the identification is of a pollen morphology that is associated with Olea capensis but may not uniquely identify Olea capensis. The APD considers Olea capensis and Olea capensis-type to be equivalent taxa. Let us therefore include this second taxon, Olea capensis-type, in our analysis and see if it makes a difference. We probably also want to include the other three categories here - all variations on the hochstetteri subspecies of Olea capensis. Because Olea capensis pollen cannot be reliably identified to the subspecies resolution, any identification as hochstetteri in pollen likely derives from local knowledge that given the age and location of the Olea capensis pollen, it must be hochstetteri. Since we're doing a broad regional analysis of Olea capensis over time, that fine distinction doesn't matter to us.


We include these new taxa below by filtering for any of the variablenames in our table where their proportion is greater than 0.05. As of November 2024, this search returns 336 occurrences - almost 200 more than our original search !

When we plot these extended data over our old data, we see that it doesn't overturn our first takeaway. It still appears that Olea capensis moved north over the last 20,000 years. But it does refine our conclusion: the movement north no longer seems as stark as before.

``` {r again}

oleacap_Harm = pollendata %>% dplyr::filter(variablename %in% oleatable$variablename) %>% dplyr::filter(!is.na(prop)) %>%
  dplyr::filter(prop > 0.05)




ggplot() +
    geom_point(mapping=aes(x=age,y=elev),alpha=0.8,color='blue',data=oleacap_Harm) +
    geom_point(mapping=aes(x=age,y=elev),alpha=0.8,color='red',data=oleacap_noHarm) +
  scale_x_reverse(limits=c(20000,0)) +
  theme_bw()



```

# Pollen Analyst Comparison 

Lastly, as a demonstration of why taxon harmonization matters, we'll compare the taxonomic systems of pollen analysts working near each other.

First we'll grab the entire sampleanalysts table from Neotoma and filter for those pollen analysts who counted pollen from Africa.


```{r analysts, warning = FALSE, message = FALSE}


text="sampleanalysts"
analysts = content(GET(paste0('https://api.neotomadb.org/v2.0/data/dbtables/',text,'?count=false&limit=999999&offset=0')))$data

analyst_mat = matrix(nrow = length(analysts),ncol=6)
for (i in seq(length(analysts))) {
  for (j in seq(6)) {
    if (!is.null(analysts[[i]][[j]])) {
      analyst_mat[i,j] = analysts[[i]][[j]]
    }
  }
}

analyst_df = as.data.frame(analyst_mat)

names(analyst_df) = c("analystid","sampleid","contactid","analystorder","recdatecreated","recdatemodified")


distinct_samples = data %>% distinct(sampleid)

filtered_an = analyst_df %>% dplyr::filter(sampleid %in% distinct_samples$sampleid)

```

Next, we'll map where these analysts worked, so that we can compare some who work near each other.

``` {r nextwel, warning = FALSE, message = FALSE}
contactcounts = filtered_an %>% group_by(contactid) %>% count() %>% arrange(desc(n))

merger = contactcounts %>% left_join(filtered_an) %>% left_join(data) %>% group_by(siteid) %>% summarize(siteid=siteid, lat=lat,long=long,contactid=contactid) %>% distinct() %>% st_as_sf(coords=c("long","lat"), crs="WGS84")


pal <- colorFactor(palette = "Set1", domain = merger$contactid)


leaflet() %>%
  addTiles() %>%
  addCircleMarkers(data = merger, 
                   radius = 5, 
                   color = ~pal(contactid), 
                   fillColor = ~pal(contactid), 
                   fillOpacity = 0.7, 
                   stroke = FALSE, 
                   popup = ~contactid)

```

Lastly, we'll do a few comparisons of people who worked near each other. Notice how the most abundant taxa for one analyst may be entirely missing for the other. This may be because they simply are naming the same plant taxa differently. 


``` {r lastl, warning = FALSE, message = FALSE}

picks = merger %>% dplyr::filter(contactid %in% c("1022","15804"))

people = content(GET("https://api.neotomadb.org/v1.5/data/contacts/1022,15804"))$data

comparison = data %>% dplyr::filter(siteid %in% picks$siteid) %>% left_join(picks) %>% group_by(contactid,variablename) %>% count() %>% pivot_wider(names_from = contactid,values_from=n)

datatable(comparison,rownames=FALSE)


picks2 = merger %>% dplyr::filter(contactid %in% c("16030","16095"))

people2 = content(GET("https://api.neotomadb.org/v1.5/data/contacts/16030,16095"))$data

comparison2 = data %>% dplyr::filter(siteid %in% picks2$siteid) %>% left_join(picks2) %>% group_by(contactid,variablename) %>% count() %>% pivot_wider(names_from = contactid,values_from=n)

datatable(comparison2,rownames=FALSE)




picks3 = merger %>% dplyr::filter(contactid %in% c("17668","262"))

people3 = content(GET("https://api.neotomadb.org/v1.5/data/contacts/17668,262"))$data

comparison3 = data %>% dplyr::filter(siteid %in% picks3$siteid) %>% left_join(picks3) %>% group_by(contactid,variablename) %>% count() %>% pivot_wider(names_from = contactid,values_from=n)

datatable(comparison3,rownames=FALSE)

```

the first way to do the PCA and clustering is to aggregate all the names any person ever used and all the names they didn't use.

```{r clusterpollenanalyst}

lats = c(-16, -16, 16, 16)
lons = c(26, 40, 40, 26) # Reordered for a rectangle

# Create a data frame with coordinates
coordinates = data.frame(lat = lats, lon = lons)

# Convert to sf object and create a polygon
coordinates_sf = coordinates %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>%
  summarise(geometry = st_combine(geometry)) %>%
  st_cast("POLYGON")

# Plot to check


merger = ungroup(merger)
merger_east = st_filter(merger,coordinates_sf)

tm_shape(osm.raster(coordinates_sf)) +
  tm_rgb() +
  tm_shape(coordinates_sf) +
  tm_borders(alpha = 0.5) +
  tm_shape(merger_east) +
  tm_dots(col="contactid",size=0.5)

wide_data = data %>% dplyr::filter(siteid %in% merger_east$siteid) %>% left_join(merger) %>% group_by(contactid,variablename) %>% count() %>% pivot_wider(id_cols = contactid, names_from = variablename, values_from = n, values_fill = 0) 

wide_data[,-1][wide_data[,-1] !=0 ] = 1

justvals = wide_data[,-1]
library(factoextra)
library(mclust)
library(cluster)




allpeople = content(GET(paste0("https://api.neotomadb.org/v1.5/data/contacts/",paste0(wide_data[[1]],collapse=","))))$data

people_mat = matrix(nrow=length(allpeople),ncol=2)

for (i in seq(length(allpeople))) {
  if(!is.null(allpeople[[i]]$contactname)) {
    people_mat[i,1] = allpeople[[i]]$contactname
  }
    if(!is.null(allpeople[[i]]$contactid)) {
    people_mat[i,2] = allpeople[[i]]$contactid
  }
}


people_df = as.data.frame(people_mat)
names(people_df) = c("contactname","contactid")


wide_data = wide_data %>% left_join(people_df)
## kmeans

    fviz_nbclust(justvals, kmeans, method = "wss") + geom_vline(xintercept = 3, linetype = 2)

        k = 3
    kmeans_clustering <- kmeans(justvals, centers = k, nstart = 20)
  
## hclust
    
      distances = dist(justvals, method = 'euclidean')
    agglomerative_clustering <- hclust(distances, method = 'average')
    
        fviz_dend(agglomerative_clustering, cex = 0.5, k = 3, color_labels_by_k = TRUE, show_labels=TRUE)
    
      
    plot(agglomerative_clustering,labels=wide_data$contactname)
 
## diana
        
    # compute divisive hierarchical clustering
    divisive_clustering <- diana(justvals)
    # Divise coefficient
    print(divisive_clustering$dc)
    
  #plot using a colors dendrogram to see our clusters with 3 groups
fviz_dend(divisive_clustering, cex = 0.5, k = 3, color_labels_by_k = TRUE, show_labels=FALSE)
plot(divisive_clustering,labels=wide_data$contactname)
##mclust

    # Create a GMM model
    dataset_mc <- Mclust(justvals)
    summary(dataset_mc)

library(ggbiplot)
pca = prcomp(justvals)    

wide_data$pc1 = pca$x[,1]
wide_data$pc2 = pca$x[,2]

ggplot(wide_data) + 
  geom_point(mapping=aes(x=pc1,y=pc2)) +
  geom_text(mapping=aes(x=(pc1+0.5),y=(pc2-0.5),label=contactname)) +
  labs(x = "PC1 (22.7%)", y = "PC2 (9.8%)") +
  theme_bw()


ggplot(wide_data) + 
  geom_point(mapping=aes(x=pc1,y=pc2)) +
  geom_text(mapping=aes(x=(pc1+0.2),y=(pc2-0.2),label=contactname)) +
  labs(x = "PC1 (22.7%)", y = "PC2 (9.8%)") +
  scale_x_continuous(limits=c(-1,4)) +
  scale_y_continuous(limits=c(-3,1)) +
  theme_bw()




ggplot(wide_data) + 
  geom_point(mapping=aes(x=pc1,y=pc2)) +
  geom_text(mapping=aes(x=(pc1+0.1),y=(pc2-0.1),label=contactname)) +
  labs(x = "PC1 (22.7%)", y = "PC2 (9.8%)") +
  scale_x_continuous(limits=c(1.6,3.5)) +
  scale_y_continuous(limits=c(-2,-0.6)) +
  theme_bw()

#pc1 biggest loadings
pca$rotation[,1][abs(pca$rotation[,1]) %in% tail(sort(abs(pca$rotation[,1])), 5)] 

#pc2 biggest loadings
pca$rotation[,2][abs(pca$rotation[,2]) %in% tail(sort(abs(pca$rotation[,2])), 5)] 

#pc3 biggest loadings
pca$rotation[,3][abs(pca$rotation[,3]) %in% tail(sort(abs(pca$rotation[,3])), 5)] 

```

the second way to cluster is to count all the names used and not used at any given site and just see who counted at that site

``` {r more-granular}


wide_data_gran = data %>% dplyr::filter(siteid %in% merger_east$siteid) %>% left_join(merger) %>% group_by(siteid,variablename) %>% count() %>% pivot_wider(id_cols = siteid, names_from = variablename, values_from = n, values_fill = 0) 

wide_data_gran[,-1][wide_data_gran[,-1] !=0 ] = 1


justvals_gran = wide_data_gran[,-1]

pca2 = prcomp(justvals_gran)    


sitecontactkey = contactcounts %>% left_join(filtered_an) %>% left_join(data) %>% distinct(contactid,siteid)

wide_data_gran$pc1 = pca2$x[,1]
wide_data_gran$pc2 = pca2$x[,2]

wide_data_gran = wide_data_gran %>% dplyr::left_join(sitecontactkey) %>% left_join(people_df)

ggplot(wide_data_gran) + 
  geom_point(mapping=aes(x=pc1,y=pc2,color=contactname)) +
  geom_text(mapping=aes(x=(pc1+0.5),y=(pc2-0.5),label=contactname,color=contactname)) +
  labs(x = "PC1 (11.7%)", y = "PC2 (5.4%)") +
  theme_bw() +
  theme(legend.position = "none") 


ggplot(wide_data_gran) + 
  geom_point(mapping=aes(x=pc1,y=pc2,color=contactname)) +
  geom_text(mapping=aes(x=(pc1+0.2),y=(pc2-0.2),label=contactname,color=contactname)) +
  labs(x = "PC1 (11.7%)", y = "PC2 (5.4%)") +
  scale_x_continuous(limits=c(-3.75,3.75)) +
  scale_y_continuous(limits=c(-3,1.5)) +
  theme_bw()  +
  theme(legend.position = "none") 




ggplot(wide_data_gran) + 
  geom_point(mapping=aes(x=pc1,y=pc2,color=contactname)) +
  geom_text(mapping=aes(x=(pc1+0.1),y=(pc2-0.1),label=contactname,color=contactname)) +
  labs(x = "PC1 (11.7%)", y = "PC2 (5.4%)") +
  scale_x_continuous(limits=c(0,3.25)) +
  scale_y_continuous(limits=c(-1,1.5)) +
  theme_bw()  +
  theme(legend.position = "none") 

#pc1 biggest loadings
pca2$rotation[,1][abs(pca2$rotation[,1]) %in% tail(sort(abs(pca2$rotation[,1])), 5)] 

#pc2 biggest loadings
pca2$rotation[,2][abs(pca2$rotation[,2]) %in% tail(sort(abs(pca2$rotation[,2])), 5)] 

#pc3 biggest loadings
pca2$rotation[,3][abs(pca2$rotation[,3]) %in% tail(sort(abs(pca2$rotation[,3])), 5)] 


```
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>