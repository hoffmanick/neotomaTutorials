db_df = distinct(db_df) %>% st_as_sf(coords=c("lon","lat"),crs=st_crs(rezes))
st_crs(db_df)
db_df = distinct(db_df) %>% st_as_sf(coords=c("lon","lat"),crs="NAD83")
db_df
db_df = as.data.frame(db_mat)
names(db_df) = c("lon","lat","siteid")
db_df = distinct(db_df) %>% st_as_sf(coords=c("lon","lat"),crs="NAD83")
db_df
unique_rez_info = st_join(db_df,rezes) %>% group_by(NAME) %>% count() %>% arrange(desc(n))
unique_rez_info
unique_rez_info = st_join(db_df,rezes) %>% group_by(NAME) %>% count() %>% arrange(desc(n)) %>% drop_na()
unique_rez_info
i=12
db = content(GET(paste0("https://api.neotomadb.org/v2.0/apps/constdb/datasets?dbid=",i)))$data
if (length(db) >0) {
print(paste("DB ID:",i))
db_mat = matrix(nrow=length(db),ncol=3)
for (m in seq(length(db))) {
if(!is.null(db[[m]]$coords[[1]])) {
db_mat[[m,1]] = db[[m]]$coords[[1]]
db_mat[[m,2]] = db[[m]]$coords[[2]]
db_mat[[m,3]] = db[[m]]$siteid
}
}
db_df = as.data.frame(db_mat)
names(db_df) = c("lon","lat","siteid")
db_df = distinct(db_df) %>% st_as_sf(coords=c("lon","lat"),crs="NAD83")
sites_by_rez = st_join(db_df,rezes) %>% group_by(NAME) %>% count() %>% arrange(desc(n)) %>% drop_na()
}
db_df
sites_by_rez
st_drop_geometry(sites_by_rez)
datatable(st_drop_geometry(sites_by_rez), rownames = )
datatable(st_drop_geometry(sites_by_rez), rownames = FALSE)
i=4
db = content(GET(paste0("https://api.neotomadb.org/v2.0/apps/constdb/datasets?dbid=",i)))$data
if (length(db) >0) {
print(paste("DB ID:",i))
db_mat = matrix(nrow=length(db),ncol=3)
for (m in seq(length(db))) {
if(!is.null(db[[m]]$coords[[1]])) {
db_mat[[m,1]] = db[[m]]$coords[[1]]
db_mat[[m,2]] = db[[m]]$coords[[2]]
db_mat[[m,3]] = db[[m]]$siteid
}
}
db_df = as.data.frame(db_mat)
names(db_df) = c("lon","lat","siteid")
db_df = distinct(db_df) %>% st_as_sf(coords=c("lon","lat"),crs="NAD83")
sites_by_rez = st_join(db_df,rezes) %>% group_by(NAME) %>% count() %>% arrange(desc(n)) %>% drop_na()}
sites_by_rez
length(sites_by_rez)
length(sites_by_rez[1])
length(sites_by_rez[[1]])
library(geojson)
geojson('https://proxyinternet.nrcan.gc.ca/arcgis/rest/services/CLSS-SATC/CLSS_Administrative_Boundaries/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')
('https://proxyinternet.nrcan.gc.ca/arcgis/rest/services/CLSS-SATC/CLSS_Administrative_Boundaries/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')
library(geojsonsf)
geojson_sf('https://proxyinternet.nrcan.gc.ca/arcgis/rest/services/CLSS-SATC/CLSS_Administrative_Boundaries/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')
canada_rezes = geojson_sf('https://proxyinternet.nrcan.gc.ca/arcgis/rest/services/CLSS-SATC/CLSS_Administrative_Boundaries/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')
canada_rezes %>% dplyr::rename(NAME ==adminAreaNameEng)
canada_rezes %>% dplyr::rename(adminAreaNameEng==NAME)
canada_rezes %>% dplyr::rename('NAME' =='adminAreaNameEng')
canada_rezes %>% dplyr::rename('NAME' = 'adminAreaNameEng')
rezes[,1]
rezes[1,]
rezes = read_sf("tl_2019_us_aiannh.shp") %>% dplyr::select(NAME)
rezes
canada_rezes %>% dplyr::rename('NAME' = 'adminAreaNameEng') %>% select(NAME)
rezes = rezes %>% dplyr::rbind(canada_rezes)
help("rbind")
rezes = rezes %>% rbind(canada_rezes)
st_transform(canada_rezes,crs="NAD83")
canada_rezes = st_transform(canada_rezes,crs="NAD83")
st_crs(canada_rezes)
rezes = rezes %>% rbind(canada_rezes)
rezes
canada_rezes
canada_rezes = canada_rezes %>% dplyr::rename('NAME' = 'adminAreaNameEng') %>% dplyr::select(NAME)
canada_rezes = st_transform(canada_rezes,crs="NAD83")
rezes = rezes %>% rbind(canada_rezes)
get_wd()
getwd()
aust_rezes = read_sf("Aboriginal_Communities_Town_Reserves_DPLH_002.shp")
aust_rezes
tm_shape(osm.raster(aust_rezes)) + tm_rgb() + tm_shape(aust_rezes) + tm_polygon()
tm_shape(osm.raster(aust_rezes)) + tm_rgb() + tm_shape(aust_rezes) + tm_polygons()
tm_shape(osm.raster(aust_rezes)) + tm_rgb() + tm_shape(aust_rezes) + tm_dots()
date = Sys.Date()
knitr::opts_chunk$set(echo=FALSE,include=TRUE,message = FALSE,warning=FALSE)
library(httr)
library(jsonlite)
library(tidyverse)
library(DT)
library(geojsonsf)
library(sf)
sf_use_s2(FALSE)
rezes = read_sf("tl_2019_us_aiannh.shp") %>% dplyr::select(NAME)
canada_rezes = geojson_sf('https://proxyinternet.nrcan.gc.ca/arcgis/rest/services/CLSS-SATC/CLSS_Administrative_Boundaries/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')
canada_rezes = canada_rezes %>% dplyr::rename('NAME' = 'adminAreaNameEng') %>% dplyr::select(NAME)
canada_rezes = st_transform(canada_rezes,crs="NAD83")
rezes = rezes %>% rbind(canada_rezes)
#aust_rezes = read_sf("Aboriginal_Communities_Town_Reserves_DPLH_002.shp")
for (i in c(2,3,4,5,6,7,10,11,12,13,14,15,17,18,19,20,22,23,25,26,27,28,29,30,31, 32,33,35,36,37,38,39,41,42)) {
db = content(GET(paste0("https://api.neotomadb.org/v2.0/apps/constdb/datasets?dbid=",i)))$data
if (length(db) >0) {
print(paste("DB ID:",i))
db_mat = matrix(nrow=length(db),ncol=3)
for (m in seq(length(db))) {
if(!is.null(db[[m]]$coords[[1]])) {
db_mat[[m,1]] = db[[m]]$coords[[1]]
db_mat[[m,2]] = db[[m]]$coords[[2]]
db_mat[[m,3]] = db[[m]]$siteid
}
}
db_df = as.data.frame(db_mat)
names(db_df) = c("lon","lat","siteid")
db_df = db_df %>% drop_na()
db_df = distinct(db_df) %>% st_as_sf(coords=c("lon","lat"),crs="NAD83")
sites_by_rez = st_join(db_df,rezes) %>% group_by(NAME) %>% count() %>% arrange(desc(n)) %>% drop_na()
#  datatable(st_drop_geometry(sites_by_rez), rownames = FALSE)
if(length(sites_by_rez)!=0) {
assign(paste0('sites_by_rez_',i),st_drop_geometry(sites_by_rez))
}
else{
print("no cultural affiliation")
}
}
}
if(exists('sites_by_rez_2')) {
datatable(sites_by_rez_2,caption="sites on federal Indian land of sites in African Pollen Database")} else{
print("no sites on federal Indian land for African Pollen Database")
}
if(exists('sites_by_rez_3')) {
datatable(sites_by_rez_3,caption="sites on federal Indian land of sites in European Pollen Database")} else{
print("no sites on federal Indian land for European Pollen Database")
}
if(exists('sites_by_rez_4')) {
datatable(sites_by_rez_4,caption="sites on federal Indian land of sites in Indo-Pacific Pollen Database")} else{
print("no sites on federal Indian land for Indo-Pacific Pollen Database")
}
if(exists('sites_by_rez_5')) {
datatable(sites_by_rez_5,caption="sites on federal Indian land of sites in Latin American Pollen Database")} else{
print("no sites on federal Indian land for Latin American Pollen Database")
}
if(exists('sites_by_rez_6')) {
datatable(sites_by_rez_6,caption="sites on federal Indian land of sites in North American Pollen Database")} else{
print("no sites on federal Indian land for North American Pollen Database")
}
if(exists('sites_by_rez_7')) {
datatable(sites_by_rez_7,caption="sites on federal Indian land of sites in Pollen Database of Russian Siberia and the Far East")} else{
print("no sites on federal Indian land for Pollen Database of Russian Siberia and the Far East")
}
if(exists('sites_by_rez_10')) {
datatable(sites_by_rez_10,caption="sites on federal Indian land of sites in FAUNMAP")} else{
print("no sites on federal Indian land for FAUNMAP")
}
if(exists('sites_by_rez_11')) {
datatable(sites_by_rez_11,caption="sites on federal Indian land of sites in Neotoma undifferentiated")} else{
print("no sites on federal Indian land for Neotoma undifferentiated")
}
if(exists('sites_by_rez_12')) {
datatable(sites_by_rez_12,caption="sites on federal Indian land of sites in North American Plant Macrofossil Database")} else{
print("no sites on federal Indian land for North American Plant Macrofossil Database")
}
if(exists('sites_by_rez_13')) {
datatable(sites_by_rez_13,caption="sites on federal Indian land of sites in Academy of Natural Sciences of Drexel University")} else{
print("no sites on federal Indian land for Academy of Natural Sciences of Drexel University")
}
if(exists('sites_by_rez_14')) {
datatable(sites_by_rez_14,caption="sites on federal Indian land of sites in NDSU Insect Database")} else{
print("no sites on federal Indian land for NDSU Insect Database")
}
if(exists('sites_by_rez_15')) {
datatable(sites_by_rez_15,caption="sites on federal Indian land of sites in Nanode")} else{
print("no sites on federal Indian land for Nanode")
}
if(exists('sites_by_rez_17')) {
datatable(sites_by_rez_17,caption="sites on federal Indian land of sites in Alaskan Archaeofaunas")} else{
print("no sites on federal Indian land for Alaskan Archaeofaunas")
}
if(exists('sites_by_rez_18')) {
datatable(sites_by_rez_18,caption="sites on federal Indian land of sites in Pondicherry Palynology Institute")} else{
print("no sites on federal Indian land for Pondicherry Palynology Institute")
}
if(exists('sites_by_rez_19')) {
datatable(sites_by_rez_19,caption="sites on federal Indian land of sites in Japanese Pollen Database")} else{
print("no sites on federal Indian land for Japanese Pollen Database")
}
if(exists('sites_by_rez_20')) {
datatable(sites_by_rez_20,caption="sites on federal Indian land of sites in Neotoma Midden Database")} else{
print("no sites on federal Indian land for Neotoma Midden Database")
}
if(exists('sites_by_rez_22')) {
datatable(sites_by_rez_22,caption="sites on federal Indian land of sites in Chinese Pollen Database")} else{
print("no sites on federal Indian land for Chinese Pollen Database")
}
if(exists('sites_by_rez_23')) {
datatable(sites_by_rez_23,caption="sites on federal Indian land of sites in Holocene Perspectives on Peatland Biogeochemistry")} else{
print("no sites on federal Indian land for Holocene Perspectives on Peatland Biogeochemistry")
}
if(exists('sites_by_rez_25')) {
datatable(sites_by_rez_25,caption="sites on federal Indian land of sites in Neotoma Testate Amoebae Database")} else{
print("no sites on federal Indian land for Neotoma Testate Amoebae Database")
}
if(exists('sites_by_rez_26')) {
datatable(sites_by_rez_26,caption="sites on federal Indian land of sites in Deep Time Palynology Database")} else{
print("no sites on federal Indian land for Deep Time Palynology Database")
}
if(exists('sites_by_rez_27')) {
datatable(sites_by_rez_27,caption="sites on federal Indian land of sites in Neotoma Biomarker Database")} else{
print("no sites on federal Indian land for Neotoma Biomarker Database")
}
if(exists('sites_by_rez_28')) {
datatable(sites_by_rez_28,caption="sites on federal Indian land of sites in Alpine Pollen Database")} else{
print("no sites on federal Indian land for Alpine Pollen Database")
}
if(exists('sites_by_rez_29')) {
datatable(sites_by_rez_29,caption="sites on federal Indian land of sites in Delorme Ostracode Database")} else{
print("no sites on federal Indian land for Delorme Ostracode Database")
}
if(exists('sites_by_rez_30')) {
datatable(sites_by_rez_30,caption="sites on federal Indian land of sites in DPDC")} else{
print("no sites on federal Indian land for DPDC")
}
if(exists('sites_by_rez_31')) {
datatable(sites_by_rez_31,caption="sites on federal Indian land of sites in Neotoma Ostracode Database")} else{
print("no sites on federal Indian land for Neotoma Ostracode Database")
}
if(exists('sites_by_rez_32')) {
datatable(sites_by_rez_32,caption="sites on federal Indian land of sites in Faunal Isotope Database")} else{
print("no sites on federal Indian land for Faunal Isotope Database")
}
if(exists('sites_by_rez_33')) {
datatable(sites_by_rez_33,caption="sites on federal Indian land of sites in Neotoma Charcoal Data")} else{
print("no sites on federal Indian land for Neotoma Charcoal Data")
}
if(exists('sites_by_rez_35')) {
datatable(sites_by_rez_35,caption="sites on federal Indian land of sites in Pollen Monitoring Programme")} else{
print("no sites on federal Indian land for Pollen Monitoring Programme")
}
if(exists('sites_by_rez_36')) {
datatable(sites_by_rez_36,caption="sites on federal Indian land of sites in PaVeLa")} else{
print("no sites on federal Indian land for PaVeLa")
}
if(exists('sites_by_rez_37')) {
datatable(sites_by_rez_37,caption="sites on federal Indian land of sites in St. Croix Research Station")} else{
print("no sites on federal Indian land for St. Croix Research Station")
}
if(exists('sites_by_rez_38')) {
datatable(sites_by_rez_38,caption="sites on federal Indian land of sites in Tropical South American Diatom Database")} else{
print("no sites on federal Indian land for Tropical South American Diatom Database")
}
if(exists('sites_by_rez_39')) {
datatable(sites_by_rez_39,caption="sites on federal Indian land of sites in Marine Dinoflagellates Database")} else{
print("no sites on federal Indian land for Marine Dinoflagellates Database")
}
if(exists('sites_by_rez_41')) {
datatable(sites_by_rez_41,caption="sites on federal Indian land of sites in Nonmarine Ostracod Distribution in Europe")} else{
print("no sites on federal Indian land for Nonmarine Ostracod Distribution in Europe")
}
if(exists('sites_by_rez_42')) {
datatable(sites_by_rez_42,caption="sites on federal Indian land of sites in East Asian Ostracode Database")} else{
print("no sites on federal Indian land for East Asian Ostracode Database")
}
length(sites_by_rez_2)
length(sites_by_rez_2[1])
length(sites_by_rez_2[[1]])
getwd()
setwd("GitHub/neotomaTutorials")
dir()
clim30_subset=stack("clim30_subset.tif")
library(raster)
clim30_subset=stack("clim30_subset.tif")
knitr::opts_chunk$set(echo = TRUE)
library(neotoma2)
library(tidyverse)
library(DT)
library(geojsonsf)
library(sf)
library(leaflet)
library(jsonlite)
library(httr)
library(ggplot2)
library(analogue)
#library(geodata)
#ibrary(elevatr)
library(raster)
library(tmap)
tanganyikaSites = get_sites(sitename = "%Tanganyika%")
plotLeaflet(tanganyikaSites)
siteidString = paste0(as.data.frame(tanganyikaSites)$siteid,collapse=",")
apiCall = paste0('https://api.neotomadb.org/v2.0/data/sites/',siteidString,'/datasets')
response = GET(apiCall)
siteMetadata = content(response)$data
siteMetadata[[1]]$site[1:5]
idx = 0
for (i in seq(length(siteMetadata))) {
for (j in seq(length(siteMetadata[[i]]$site$datasets))) {
idx = idx + 1
}
}
siteMetadata_mat = matrix(nrow=idx,ncol=10)
idx2 = 0
for (i in seq(length(siteMetadata))) {
for (j in seq(length(siteMetadata[[i]]$site$datasets))) {
idx2 = idx2 + 1
for (k in seq(10)) {
if (!is.null(siteMetadata[[i]]$site[[k]])) {
siteMetadata_mat[[idx2, k]] = siteMetadata[[i]]$site[[k]]
}
}
#    if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$doi[[1]])) {
#       siteMetadata_mat[[idx2, 11]] = siteMetadata[[i]]$site$datasets[[j]]$doi[[1]]
#   }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[1]])) {
#      siteMetadata_mat[[idx2, 12]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[1]]
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[2]])) {
#      siteMetadata_mat[[idx2, 13]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[2]]
#    }
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[3]])) {
#      siteMetadata_mat[[idx2, 14]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[3]]
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$database)) {
#      siteMetadata_mat[[idx2, 15]] = siteMetadata[[i]]$site$datasets[[j]]$database
#  }
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetid)) {
#      siteMetadata_mat[[idx2, 16]] = siteMetadata[[i]]$site$datasets[[j]]$datasetid
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetpi[[1]]$contactname)) {
#      siteMetadata_mat[[idx2, 17]] = siteMetadata[[i]]$site$datasets[[j]]$datasetpi[[1]]$contactname
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasettype)) {
#      siteMetadata_mat[[idx2, 18]] = siteMetadata[[i]]$site$datasets[[j]]$datasettype
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetnotes)) {
#      siteMetadata_mat[[idx2, 19]] = siteMetadata[[i]]$site$datasets[[j]]$datasetnotes
#  }
}
}
siteMetadata_df = as.data.frame(siteMetadata_mat)
names(siteMetadata_df) = c("siteid","sitename","sitedescription","sitenotes","geography","altitude","collectionunitid","collectionunit","handle","unittype")
#names(siteMetadata_df) = c("siteid","sitename","sitedescription","sitenotes","geography","altitude","collectionunitid","collectionunit","handle","unittype","dataset_doi","dataset_agerange_units","dataset_ageold","dataset_ageyoung","database","datasetid","datasetpi","datasettype","datasetnotes")
siteMetadata_df = distinct(siteMetadata_df)
idx = 0
for (i in seq(length(siteMetadata))) {
for (j in seq(length(siteMetadata[[i]]$site$datasets))) {
idx = idx + 1
}
}
siteMetadata_mat = matrix(nrow=idx,ncol=10)
idx2 = 0
for (i in seq(length(siteMetadata))) {
for (j in seq(length(siteMetadata[[i]]$site$datasets))) {
idx2 = idx2 + 1
for (k in seq(10)) {
if (!is.null(siteMetadata[[i]]$site[[k]])) {
siteMetadata_mat[[idx2, k]] = siteMetadata[[i]]$site[[k]]
}
}
#    if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$doi[[1]])) {
#       siteMetadata_mat[[idx2, 11]] = siteMetadata[[i]]$site$datasets[[j]]$doi[[1]]
#   }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[1]])) {
#      siteMetadata_mat[[idx2, 12]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[1]]
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[2]])) {
#      siteMetadata_mat[[idx2, 13]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[2]]
#    }
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[3]])) {
#      siteMetadata_mat[[idx2, 14]] = siteMetadata[[i]]$site$datasets[[j]]$agerange[[1]][[3]]
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$database)) {
#      siteMetadata_mat[[idx2, 15]] = siteMetadata[[i]]$site$datasets[[j]]$database
#  }
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetid)) {
#      siteMetadata_mat[[idx2, 16]] = siteMetadata[[i]]$site$datasets[[j]]$datasetid
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetpi[[1]]$contactname)) {
#      siteMetadata_mat[[idx2, 17]] = siteMetadata[[i]]$site$datasets[[j]]$datasetpi[[1]]$contactname
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasettype)) {
#      siteMetadata_mat[[idx2, 18]] = siteMetadata[[i]]$site$datasets[[j]]$datasettype
#  }
#
#  if (!is.null(siteMetadata[[i]]$site$datasets[[j]]$datasetnotes)) {
#      siteMetadata_mat[[idx2, 19]] = siteMetadata[[i]]$site$datasets[[j]]$datasetnotes
#  }
}
}
siteMetadata_df = as.data.frame(siteMetadata_mat)
names(siteMetadata_df) = c("siteid","sitename","sitedescription","sitenotes","geography","altitude","collectionunitid","collectionunit","handle","unittype")
#names(siteMetadata_df) = c("siteid","sitename","sitedescription","sitenotes","geography","altitude","collectionunitid","collectionunit","handle","unittype","dataset_doi","dataset_agerange_units","dataset_ageold","dataset_ageyoung","database","datasetid","datasetpi","datasettype","datasetnotes")
siteMetadata_df = distinct(siteMetadata_df)
siteGeo_sf = geojson_sf(siteMetadata_df$geography)
siteMetadata_sf = cbind(siteGeo_sf,siteMetadata_df)
pointSites = siteMetadata_sf[st_geometry_type(siteMetadata_sf) == "POINT",] %>% distinct(siteid, .keep_all = TRUE)
polySites = siteMetadata_sf[st_geometry_type(siteMetadata_sf) == "POLYGON",] %>% distinct(siteid, .keep_all = TRUE)
text="collectionunits"
collunits = content(GET(paste0('https://api.neotomadb.org/v2.0/data/dbtables/',text,'?count=false&limit=99999&offset=0')))$data
collunit_mat = matrix(nrow=length(collunits),ncol=20)
for (i in seq(length(collunits))) {
for (j in seq(20)) {
if (!is.null(collunits[[i]][[j]])) {
collunit_mat[[i,j]] = collunits[[i]][[j]]
}
}
}
collunit_df = collunit_mat %>% as.data.frame()
names(collunit_df) = c("collectionunitid","handle","siteid","colltypeid","depenvtid","collunitname","colldate","colldevice","gpslatitude","gpslongitude","gpsaltitude","gpserror","waterdepth","substrateid","slopeaspect","slopeangle","location","notes","recdaterecreated","recdatemodified")
filtered_colls = collunit_df %>% dplyr::filter(collectionunitid %in% siteMetadata_df$collectionunitid)
filteredColl_sf = collunit_df %>% dplyr::filter(collectionunitid %in% siteMetadata_df$collectionunitid) %>% st_as_sf(coords=c("gpslongitude","gpslatitude"), crs="WGS84")
#just first ten cols
datatable(st_drop_geometry(filteredColl_sf)[c(1:3,5:10,15)],rownames=FALSE)
pal <- colorFactor(palette = "Set1", domain = siteMetadata_df$siteid)
leaflet() %>%
addTiles() %>%
addPolygons(data = polySites,
color = "red",
weight = 2,
fillColor = ~pal(siteid),
fillOpacity = 0.45,
popup = ~siteid)  %>%
addCircleMarkers(data = pointSites,
radius = 5,
color = "black",
fillColor = ~pal(siteid),
fillOpacity = 0.7,
stroke = TRUE,
weight = 1,
popup = ~siteid)   %>%
addCircleMarkers(data = filteredColl_sf,
radius = 3,
color = "white",
fillColor = ~pal(siteid),
fillOpacity = 1,
stroke = TRUE,
weight = 1,
popup = ~collectionunitid)
samps = samples(get_downloads(get_datasets(tanganyikaSites)))
pollen = samps %>% dplyr::filter(datasettype=="pollen" & element == "pollen")
toptaxa = pollen %>% group_by(variablename) %>% count() %>% arrange(desc(n)) %>% head(n=6)
count_coll = pollen %>% dplyr::filter(variablename %in% toptaxa$variablename) %>% dplyr::select(collunitid,age,variablename,value) %>%
group_by(collunitid,age) %>%
dplyr::mutate(pollcount = sum(value, na.rm=TRUE)) %>%
ungroup() %>%
group_by(collunitid,age,variablename) %>%
mutate(sum_poll = sum(value,na.rm=TRUE)) %>%
ungroup() %>%
group_by(variablename) %>%
mutate(prop = sum_poll / pollcount) %>%
dplyr::select(collunitid, age, variablename, prop) %>%
mutate(prop = as.numeric(prop)) %>%
drop_na(age) %>%
distinct()
counts_coll = tidyr::pivot_wider(count_coll,
id_cols = c(age,collunitid),
names_from = variablename,
values_from = prop,
values_fill = 0)
counts_coll = counts_coll %>% left_join(filtered_colls, by = join_by(collunitid == collectionunitid))
count_site = pollen %>% dplyr::filter(variablename %in% toptaxa$variablename) %>% dplyr::select(siteid,age,variablename,value) %>%
group_by(siteid,age) %>%
dplyr::mutate(pollcount = sum(value, na.rm=TRUE)) %>%
ungroup() %>%
group_by(siteid,age,variablename) %>%
mutate(sum_poll = sum(value,na.rm=TRUE)) %>%
ungroup() %>%
group_by(variablename) %>%
mutate(prop = sum_poll / pollcount) %>%
dplyr::select(siteid, age, variablename, prop) %>%
mutate(prop = as.numeric(prop)) %>%
drop_na(age) %>%
distinct()
counts_site = tidyr::pivot_wider(count_site,
id_cols = c(age,siteid),
names_from = variablename,
values_from = prop,
values_fill = 0)
counts_site = counts_site %>% left_join(as.data.frame(tanganyikaSites), by=join_by(siteid==siteid))
counts_coll = counts_coll %>% dplyr::mutate(gpslatitude = round(as.numeric(gpslatitude),6))
counts_coll = counts_coll %>% dplyr::mutate(gpslongitude = round(as.numeric(gpslongitude),6))
#clim2 <- geodata::worldclim_global(var = 'bio', res = 0.5, path=tempdir())
#lc_tree = landcover(var='trees',path=tempdir())
#lc_grass =  landcover(var='grassland',path=tempdir())
lats = c(-3,-3,-9,-9) %>% as.data.frame()
lons = c(28,32,28,32) %>% as.data.frame()
coordinates = lats %>% cbind(lons)
names(coordinates) = c("lat","lon")
coordinates = coordinates %>% st_as_sf(coords=c("lon","lat"), crs="WGS84") %>% mutate(dummyID = 1) %>% group_by(dummyID) %>% dplyr::summarize() %>% st_cast("POLYGON")
#lc_tree_raster <- raster("lc_eraster.tif")
#lc_grass_raster <- raster("lc_grass_raster.tif")
clim30_subset=stack("clim30_subset.tif")
getwd()
clim30_subset
list.files()
rgdal::gdalDrivers()
install.packages('raster')
install.packages("raster")
install.packages("raster")
